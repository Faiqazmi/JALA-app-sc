# -*- coding: utf-8 -*-
"""Survival Rate JALA - ML Development.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1L70HMDkG_I1NUMfYJNazIi4RqS8MQPWy
"""

!pip install pycaret

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import datetime

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

"""# Data Preparation"""

data = pd.read_csv('/content/sample_data/Jala Test - Survival Rate 5.csv')
data

data.info()

"""# Data Investigation"""

data.isnull().sum()

"""Kolom yang perlu diperhatikan untuk di adjust:
- Remark: **Dihapus**
- initial_age
- limit_weight_per_area
- target_cultivation_day
- target_size
- ordered_at: **Dihapus**
- total_seed_type
- hatchery_name: **Dihapus**
- pond_depth
- status: Di Adjust Ulang
- selling_price: **Dihapus**
"""

# Menambahkan pengecekan untuk nilai selain NaN yang mungkin berbentuk string invalid
invalid_values = ['nan', 'none', 'n/a', 'na']
df_cleaned = data.applymap(lambda x: pd.NA if isinstance(x, str) and x.lower() in invalid_values else x)

df_cleaned.isna().sum()

# Menghapus beberaopa dari DataFrame
data.drop(columns=['species_id','remark', 'ordered_at', 'ordered_at', 'hatchery_id', 'selling_price', 'hatchery_name', 'pond_depth', 'pond_length', 'pond_width', 'pond_name'], inplace=True)

"""# Data Wrangling

## Perubahan tipe data
"""

# Mengkonversikan kolom waktu menjadi datetime
time_columns = ['finished_at','started_at','created_at', 'updated_at', 'extracted_at', 'ordered_at', 'harvested_at', 'updated_at.1', 'created_at.1']

for col in time_columns:
    if col in data.columns:
        data[col] = pd.to_datetime(data[col], errors='coerce')

# Mengkonversikan data id menjadi tipe data String
id_columns = [col for col in data.columns if 'id' in col]
data[id_columns] = data[id_columns].astype(str)

"""## Rename Data Column"""

# Perubahan nama kolom
data.rename(columns={'survival_rate%': 'calculated_sr'}, inplace=True)

"""## Drop Outlier/Anomali SR"""

data[data['calculated_sr']>100]

# Hapus baris dengan survival_rate% > 100
data = data[data['calculated_sr'] <= 100]
data = data.reset_index(drop=True)

data = data.dropna(subset=['harvested_at']).reset_index(drop=True)

"""## Data Imputation"""

invalid_values = ['nan', 'none', 'n/a', 'na']
data = data.applymap(lambda x: pd.NA if isinstance(x, str) and x.lower() in invalid_values else x)

data.isna().sum()

columns = ['initial_age',
 'limit_weight_per_area',
 'target_cultivation_day',
 'target_size',
 'total_seed_type',
 'pond_length',
 'pond_depth',
 'status']

"""### DI: initial_age"""

data[data['initial_age'].isna()]

"""### DI: limit_weight_per_area"""

data.describe()['limit_weight_per_area']

# Melakukan imputasi data pada kolom 'limit_weight_per_area'
data['limit_weight_per_area'].fillna(data['limit_weight_per_area'].median(), inplace=True)

"""### DI: target_cultivation_day"""

data.describe()['target_cultivation_day']

data[data['target_cultivation_day'].isna()]

# Mengimputasi nilai kosong dengan median
data['target_cultivation_day'].fillna(data['target_cultivation_day'].median(), inplace=True)

"""### DI: target_size"""

data.isnull().sum()

# Mengimputasi nilai kosong dengan median
data['target_size'].fillna(data['target_size'].median(), inplace=True)

"""### DI: initial_age dan total_seed_type"""

data = data.dropna(subset=['initial_age', 'total_seed_type'])

data.isnull().sum()

data.info()

"""# Feature Engineering and Analysis"""

data['cultivation_days'] = (data['finished_at'] - data['started_at']).dt.days

data['exceeds_3/4_months'] = data['cultivation_days'].apply(lambda x: 'yes' if x > 120 else 'no')

# Produksi per meter persegi (total harvest / area)
data['production_per_area'] = data['total_harvest'] / data['area']

# Menghitung total seed per area (jumlah benih per meter persegi)
data['total_seed_per_area'] = data['total_seed'] / data['area']

# Berat rata-rata per benih (berat total harvest / total benih)
data['weight_per_seed'] = data['weight'] / data['total_seed']

# Menghitung total berat per meter persegi (total_weight_per_area)
data['total_weight_per_area'] = data['total_harvest'] / data['area']

# Menandai apakah berat total per area melebihi limit atau masih dalam batas
data['weight_status'] = data.apply(
    lambda row: 'Exceeded' if row['total_weight_per_area'] > row['limit_weight_per_area'] else 'Within Limit',
    axis=1
)

# Hitung padat tebar
data['density'] = data['total_seed'] / data['area']

# melabelkan apakah target cultivation_days tercapai
data['cultivation_target_status'] = data.apply(
    lambda row: 'Target Achieved' if row['cultivation_days'] <= row['target_cultivation_day'] else 'Target Not Achieved',
    axis=1
)

# melabelkan apakah target size tercapai
data['size_target_status'] = data.apply(
    lambda row: 'Target Achieved' if row['size'] >= row['target_size'] else 'Target Not Achieved',
    axis=1
)

# Fungsi untuk merapikan status
# Full Table Cycle
def clean_status(status):
    if pd.isna(status):  # Menangani nilai NaN
        return 'Unknown'
    if 'Transfer' in status:
        return 'Transfer'
    elif 'Partial' in status or 'Parsial' in status:
        return 'Partial'
    elif 'Finishing' in status or 'Pengesatan' in status:
        return 'Finishing'
    elif status == 'Failed':
        return 'Failed'
    elif status == 'Full':
        return 'Full'
    else:
        return 'Other'  # Jika ada kategori yang belum dikelompokkan

# Terapkan fungsi ke kolom 'status'
data['cleaned_status'] = data['status'].apply(clean_status)

# Kategorisasi padat tebar
def categorize_density(density):
    if density <= 80:
        return "Rendah (≤80 PL/m²)"
    elif 80 < density <= 200:
        return "Sedang (80-200 PL/m²)"
    else:
        return "Tinggi (>200 PL/m²)"
data['density_category'] = data['density'].apply(categorize_density)

# kategorisasi evaluais sr
def evaluate_sr(row):
    if row['density'] <= 80 and row['calculated_sr'] >= 50:
        return "Memenuhi Standar JALA"
    elif 80 < row['density'] <= 200 and row['calculated_sr'] >= 50:
        return "Memenuhi Standar JALA"
    elif row['density'] > 200 and row['calculated_sr'] > 56.17:
        return "Memenuhi Standar JALA"
    else:
        return "Tidak Memenuhi Standar"
data['sr_evaluation'] = data.apply(evaluate_sr, axis=1)

"""# Feature Transformation"""

data.reset_index(drop=True, inplace=True)
data.info()

data.select_dtypes(include=['object']).head()

data = pd.get_dummies(data, columns=['sr_evaluation'], prefix=['sr_evaluation'])
data = pd.get_dummies(data, columns=['cultivation_target_status'], prefix=['cultivation_target_status'])
data = pd.get_dummies(data, columns=['weight_status'], prefix=['weight_status'])
data = pd.get_dummies(data, columns=['exceeds_3/4_months'], prefix=['exceeds_3/4_months'])
data = pd.get_dummies(data, columns=['cleaned_status'], prefix=['cleaned_status'])
data = pd.get_dummies(data, columns=['density_category'], prefix=['density_category'])
data = pd.get_dummies(data, columns=['total_seed_type'], prefix=['total_seed_type'])
data = pd.get_dummies(data, columns=['subscription_type'], prefix=['subscription_type'])

df = data.select_dtypes(include=['float64', 'int64', 'bool'])

"""# Feature Selection"""

X = df.drop(columns=['calculated_sr'])
y = df['calculated_sr']

X.columns

"""## Pearson Correlation"""

df_numeric = data.select_dtypes(include=['float64', 'int64', 'bool'])

# Compute the correlation matrix
correlation_matrix = df_numeric.corr()

# Select the column 'calculated_sr' and its correlation with others
calculated_sr_correlation = correlation_matrix[['calculated_sr']]

# Plot the heatmap for calculated_sr correlation
plt.figure(figsize=(2, 8))
sns.heatmap(calculated_sr_correlation, annot=True, cmap='coolwarm', vmin=-1, vmax=1, cbar=True)
plt.title('Correlation with calculated_sr')
plt.show()

# Sort the correlation values in descending order
sorted_correlation = calculated_sr_correlation.sort_values(by='calculated_sr', ascending=False)

# Plot the heatmap for sorted correlation with calculated_sr
plt.figure(figsize=(2, 8))
sns.heatmap(sorted_correlation, annot=True, cmap='coolwarm', vmin=-1, vmax=1, cbar=True)
plt.title('Correlation with calculated_sr (Sorted)')
plt.show()

sorted_correlation

df_numeric = data.select_dtypes(include=['float64', 'int64', 'bool'])

# Compute the correlation matrix
correlation_matrix = df_numeric.corr()

# Select the column 'calculated_sr' and its correlation with others
calculated_sr_correlation = correlation_matrix

# Plot the heatmap for calculated_sr correlation
plt.figure(figsize=(30, 10))
sns.heatmap(calculated_sr_correlation, annot=True, cmap='coolwarm', vmin=-1, vmax=1, cbar=True)
plt.title('Correlation with calculated_sr')
plt.show()

calculated_sr_correlation = correlation_matrix[['sr_evaluation_Memenuhi Standar JALA']].sort_values(by='sr_evaluation_Memenuhi Standar JALA', ascending=False)
# Plot the heatmap for calculated_sr correlation
plt.figure(figsize=(6, 8))
sns.heatmap(calculated_sr_correlation, annot=True, cmap='coolwarm', vmin=-1, vmax=1, cbar=True)
plt.title('Correlation with calculated_sr')
plt.show()

"""## Wrapper Methods"""

from sklearn.feature_selection import RFE
from sklearn.linear_model import LinearRegression

model = LinearRegression()
rfe = RFE(model, n_features_to_select=5)  # Pilih 5 fitur terbaik
rfe.fit(X, y)

selected_features = X.columns[rfe.support_]
print("Selected features:", selected_features)

"""## Tree-Based Models"""

from sklearn.ensemble import RandomForestRegressor
import pandas as pd

model = RandomForestRegressor()
model.fit(X, y)

# Feature importance
importance = model.feature_importances_
feature_importance = pd.DataFrame({'Feature': X.columns, 'Importance': importance})
feature_importance.sort_values(by='Importance', ascending=False, inplace=True)
feature_importance

"""## Cek Multikolinearitas"""

X = df[['density_category_Rendah (≤80 PL/m²)', 'total_seed_type_gross', 'weight_per_seed', 'initial_age', 'exceeds_3/4_months_no', 'target_size', 'total_seed_per_area', 'density']]
y = df['calculated_sr']

import pandas as pd
import numpy as np
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Assuming the dataset is already loaded as `df`
# Define features (X) and target (y)
X = df[['density_category_Rendah (≤80 PL/m²)', 'total_seed_type_gross', 'weight_per_seed',
        'initial_age', 'exceeds_3/4_months_no', 'target_size', 'total_seed_per_area', 'density']]

# Convert boolean columns to numeric (int) before calculating VIF
# This is to avoid the TypeError related to 'isfinite'
for col in X.select_dtypes(include=['bool', 'object']).columns:
    X[col] = X[col].astype(int)

# Calculate VIF for each feature
vif_data = pd.DataFrame()
vif_data["Feature"] = X.columns
vif_data["VIF"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]

vif_data

"""# Feature Scalling & Data Splitting"""

from pycaret.regression import *

data_scaled = df[['density_category_Rendah (≤80 PL/m²)', 'total_seed_type_gross',
                  'weight_per_seed', 'initial_age', 'exceeds_3/4_months_no',
                  'target_size', 'total_seed_per_area', 'calculated_sr']]

# Setup PyCaret untuk regression task
exp = setup(data=data_scaled, target='calculated_sr', session_id=42, normalize=True)

# Lakukan pemodelan dan pilih model terbaik
best_model = compare_models()

best_model

# Tuning model (opsional)
tuned_model = tune_model(best_model)

plot_model(tuned_model)

plot_model(tuned_model, plot = 'error')

plot_model(tuned_model, plot='feature')

evaluate_model(tuned_model)

final_lightgbm = finalize_model(tuned_model)
final_lightgbm

print(final_lightgbm)

predict_model(tuned_model)

save_model(final_lightgbm,'Final Lightgbm Model Jan2025')